# 爬虫与反爬虫总结

## 请求Header
一些简单的爬虫没有添加合适的Header就发起访问，比如：没有user-agent，没有Referer或者Referer不是本网站。  
通过检测并过滤即可禁掉这类爬虫。  
**缺点**：user-agent很容易添加，Referer也可以自己根据所爬网站填写，很容易绕过。

## 行为判断
如果爬虫做了Header处理，接下来可以基于行为判断。  
ip访问次数过多，短时间内ip大量访问。  
针对此种情况，可以在检测到这种行为之后禁掉这些ip，临时禁掉或者永久性禁掉  
**缺点**：过于依赖ip，如果爬虫使用ip代理池均分请求，很难检测  

## 禁掉公共的ip代理池
网上有一些公有的ip代理池，既然爬虫可以利用，那么反爬虫也可以利用。通过搜集公有ip代理池，直接禁掉公有ip代理池中的ip，使得攻击者不得不维护自己的ip代理池，攻击成本增加  
**缺点**：不能检测攻击者自己维护的ip代理池，攻击者也可以通过tor匿名网络来访问

## ajax获取资源
用户点击之后才会通过ajax请求资源，这样可以禁掉直接访问资源地址的爬虫
**缺点**：攻击者可能通过分析ajax行为得到资源地址，攻击者也可以使用可以模拟用户操作的模块来得到资源(如phantomjs)  

## 添加验证机制  
只要验证机制不是太简单，应该就比较难绕过了，比如稍微复杂点的验证码  

## 总结
反爬虫的核心就在于：只允许普通人应该有的行为  
如果可以做到让爬虫只能完全模拟用户操作来获取资源，那就算是成功的反爬虫了  


2017/9/27  
